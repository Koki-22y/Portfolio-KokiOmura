# AI プロンプト品質研修 スライドアウトライン
## 全50枚構成

---

## 第1部：導入＋構造化・MECE（90分）

### スライド1：タイトル
- 研修タイトル：「AIを監督する力を身につける」
- サブタイトル：対話設計能力と品質管理能力の習得

### スライド2：研修の背景
- 生成AIを「うまく使いこなす」とは？
- 出力物をそのまま使うのではない
- 「対話設計能力」と「品質管理能力」が必要

### スライド3：研修の目標
- AIへの指示出しにおける根本的な思考法の習得
- 出力結果の検証スキル
- AIの内部構造理解に基づいた編集スキル

### スライド4：研修の全体像
- 講義6時間 + ワークショップ6時間 = 計12時間
- アウトプット中心（ゲーム性あり）
- 2日間構成

### スライド5：TCREIフレームワーク概要
- Google Prompt Engineering courseのテクニック
- T: Task（タスク）
- C: Context（文脈）
- R: References（参照）
- E: Evaluation（評価）
- I: Iteration（反復）

### スライド6：研修の3部構成
- 【前半】思考の整理法（TCR）
- 【中盤】評価と検証（E）
- 【後半】仕組みと編集（I）

### スライド7：MECEとは？
- Mutually Exclusive, Collectively Exhaustive
- 「漏れなく、ダブりなく」
- なぜMECEが重要か？

### スライド8：構造化とは？
- 料理に例えると：「何を作るかに向けて、材料・工程を整理すること」
- 曖昧な指示 → 焦点の定まらない結果

### スライド9：構造化されていない例（Before）
- 「なんか美味しいもの作って」
- 目的：不明（誰が食べる？いつ？）
- 文脈：不明（誰と食べる？）
- 制約：不明（時間・予算・道具）

### スライド10：構造化された例（After）- 目的設定
- 目的（タスク）を決める
- 例：「平日の夜に、30分以内で作れる2人分の夕食」

### スライド11：構造化された例（After）- 文脈・制約整理
- 人数：大人2人
- 予算：1人500円以内
- 調理器具：フライパン1つ
- 食事制限：なし

### スライド12：構造化された例（After）- 要素分解
- 主菜 / 副菜 / 主食
- 主菜：鶏肉／豚肉／豆腐
- 調理法：焼く／炒める／煮る

### スライド13：構造化された例（After）- 判断・改善
- 時間がかかりすぎる → 工程を減らす
- 味が単調 → 調味を調整
- 構造化により改善点が見える

### スライド14：MW①「今晩何食べる？」
- ミニワークショップ（15分）
- 材料などの前提を提示
- 構成要素の練り出しから整理まで

### スライド15：フェルミ推定でTCR思考を学ぶ
- フェルミ推定ができると TCR の整理ができる
- LLMとの対話においても有益

### スライド16：フェルミ推定の例題
- 「日本にある電柱の数は？」
- 目的：日本にある電柱の数を推定する

### スライド17：アプローチの設定
- 日本の面積 × 1km²あたりの電柱数
- 都市部と田舎で分けて推定

### スライド18：必要な要素の洗い出し
- 都市面積（全体の10%）= 38,000km²
- 田舎面積（全体の90%）= 342,000km²
- 都市：50m×50mで1本
- 田舎：150m×150mで1本

### スライド19：計算と結果
- 都市本数：約15,200,000本
- 田舎本数：約15,200,000本
- 合計：約30,400,000本

### スライド20：フェルミ推定 = TCRの整理
- タスク策定：日本にある電柱の数を推定する
- 文脈整理：日本の面積、都市/田舎の比率
- 制約・条件策定：密度の仮定

---

## 第2部：プロンプト分解と出力評価（90分）

### スライド21：TCREIフレームワーク詳細
- Google Prompt Engineeringコースのテクニック
- 覚え方：「タ・ブン・サン・ヒョウ・ク」→「多分、三票、来る」

### スライド22：T - Task（タスク）
- 「何をAIにしてほしいか」を精密に言語化
- 文章生成？画像生成？表生成？動画生成？
- 曖昧な指示 → 焦点の定まらない結果

### スライド23：Task の良い例・悪い例
- ❌「市場動向を分析せよ」
- ⭕「再生可能エネルギー分野における第4四半期の新興市場動向について、太陽光および風力技術に焦点を当て、直近2会計年度の定量データを用いて簡潔な分析を生成せよ」

### スライド24：C - Context（文脈）
- 必要不可欠な足場（コンテキスト）を提供
- あなたの年齢、役職
- 出力の使用用途
- ペルソナ設定（例：「CTOの立場で回答せよ」）

### スライド25：Context の例
- 「経験豊富な法務顧問というペルソナを想定し、革新的な機械学習アルゴリズムを立ち上げるSaaSスタートアップにおける主要な知的財産上の検討事項を整理したメモランダムを作成せよ」

### スライド26：R - References（参照）
- 具体例と制約条件を与える
- 「300字以内で」
- 「上司向けの敬語を使った丁寧なメール」
- 「シンプルで端的に」

### スライド27：E - Evaluation（評価）
- AIの応答を受け取った後の厳密な評価
- 単なる受容ではなく、綿密な分析と吟味

### スライド28：評価の3つの確認ポイント
- 出力は定義されたタスクに十分対応しているか？
- 提示した文脈は適切に活用されているか？
- 提示した条件や制約と整合しているか？

### スライド29：I - Iteration（反復）
- 評価結果を踏まえ、プロンプトを改良
- 反復こそが最適なプロンプトを鍛え上げる炉
- わずかな調整が出力の質を大きく向上させる

### スライド30：MW②「TCR評価・作成」
- ミニワークショップ（15分）
- TCRを整理したプロンプトを作成
- 出力が意図したTCRと合っているか確認

---

## 第3部：ハルシネーションと検証判断（90分）

### スライド31：ハルシネーションとは？
- AIが事実ではない情報をもっともらしく生成する現象
- LLMは統計的な確率に基づいて「次の言葉を予測している」だけ

### スライド32：ハルシネーションの有名な例
- ChatGPTが「Strawberry」のrの数を数えられない
- 文字を数えるのではなく、確率的に回答を生成

### スライド33：ハルシネーションチェックが必要な状況①
- 回答の事実性が重要な場合
  - アカデミック用途
  - ビジネス用途のファクトチェック
- 最新の情報が求められる場合

### スライド34：ハルシネーションチェックが必要な状況②
- 簡単にググって出てこないニッチな内容
- RAGがあっても学習データに情報がない可能性
- 数字が絡む質問（LLMは計算に弱い）

### スライド35：ハルシネーションチェックが必要な状況③
- 歴史的事実など解釈が分かれる分野
  - 例：ChatGPT（米国）とDeepSeek（中国）で回答が異なる
- 条件が複雑で例外が多い分野

### スライド36：事実と意見を区別する
- 事実：エビデンスをもって証明できる、普遍的で議論の余地がない
- 意見：「正しい」も「間違い」もない、信条・態度・価値観・感情の表現

### スライド37：事実と意見の例
- 事実：「犬は哺乳類である」→ 議論の余地なし
- 意見：「第二次世界大戦はひどいものだった」→ 何をもって「ひどい」とするか不明瞭

### スライド38：言葉のバイアスに注意
- 「AIは人間の仕事をなくす危険な存在だ」
- 100の仕事のうち1がAIに代替 →「奪う」は正しいか？
- 言葉の持つバイアスを識別する力

### スライド39：MW③「Kahoot + 3分ファクトチェック」
- 例題で検証が必要かをYES/NOで回答
- なぜ検証が必要かの解説

### スライド40：ファクトチェック・スプリント
- Phase1：個人判断（5分）
- Phase2：超短時間検証（10分）
- Phase3：共有と解説（10分）

### スライド41：ファクトチェックの例題
- 「オンライン教育は対面授業より学習効果が高い」
- 「モンテッソーリ教育に効果はない」
- 検証のポイント：地域、評価基準の明示

### スライド42：検証の心構え
- 検証は情報の確度を100に近づける作業であって100にする作業ではない
- 「結論を保留する」判断も成果
- 検証不能だったこと自体も成果

---

## 第4部：LLMの限界理解と編集スキル（90分）

### スライド43：コンテキストウィンドウとは？
- 過去の会話で交換した情報を保持できる範囲
- ホワイトボードのようなもの
- モデルによってサイズが異なる

### スライド44：トークンとは？
- LLMが文章を処理する際の最小単位
- 英語：アルファベット単位
- 日本語：ひらがな、漢字など

### スライド45：トークナイゼーションの例
- 「私はAIを研究している。」
- → 私 / は / AI / を / 研究 / して / いる / 。
- モデルによってトークナイザーが異なる

### スライド46：コンテキストウィンドウの限界
- 大きすぎると計算コストが爆増
- ChatGPTはGoogle検索の10倍の電力を使用
- 情報過多でトークンの関連付けに混乱

### スライド47：Middle-Forgetting現象
- コンテキストの最初と最後を重視
- 中間情報を欠落させてしまう現象
- 長いロープと短いロープを両端で揃えるイメージ

### スライド48：FIFO方式と記憶の薄れ
- 古いトークン情報から自動削除
- ChatGPT, Geminiなど
- Claudeなどは圧縮して保持（Context Compression）

### スライド49：編集機能の活用
- 意図通りに伝わっていなければプロンプトを修正
- 余計な情報処理を減らす
- 編集 → 前提の修正・ノイズ除去
- 新規メッセージ → 思考を進める・深める

### スライド50：なぜ冗長な答えが出るか？
- 確率的に「よくありそうな文章」を生成
- 意味を増やさない語を追加しても確率が下がらない
- 「簡略化」にインセンティブがない

### スライド51：冗長な表現の例
- 「推測して予想している」→ 簡略化可能
- 「短く端的に」→ 重複表現
- 似た単語どうしのLLM内での距離が近い

### スライド52：情報削減 Phase1 - グループ化
- 似た内容をグループ化
- 例：「簡単に」≒「直感的に」
- 「分かりやすく」≒「理解しやすい」
- 「シンプルで」≒「複雑な手順を必要としません」

### スライド53：情報削減 Phase2 - 削除・統合
- あってもなくても伝わるなら削除
- 言い換え・統合を検討
- 例：「非常にシンプルです」に統合

### スライド54：MW④「文章・スライド添削」
- Gensparkで生成した資料を編集
- 余分な情報を削ぎ取る
- 統合・言い換えを実践

### スライド55：重要なマインドセット
- 「生成されたものをそのまま使うな！」
- 人間が監督として入ることで完成度を高める
- AIに使われるのではなく、AIを監督する

---

## 2日目ワークショップ（6時間）

### スライド56：ワークショップ概要
- 自身の所属する会社の営業資料を作成
- Gensparkでプロンプト入力（TCREI活用）
- Gemini / Google NotebookLMも活用

### スライド57：ワークショップの流れ
1. TCREIを踏まえたプロンプト設計
2. 資料生成
3. 出力された資料の情報修正・削減
4. ファクトチェック
5. デザイン調整（画像生成スキル活用）

### スライド58：まとめ - 3つの力
- 対話設計能力（TCR）
- 品質管理能力（E）
- 編集能力（I）

### スライド59：研修で得られるスキル
- AIの出力に対する妥当性・品質の判断
- 不足している観点の判断
- MECE性の確認
- 事実と意見の区別

### スライド60：最後に
- 「AIに使われる」のではなく「AIを監督/コントロール・編集する」
- 継続的な実践で習得
- 研修後も活用を！

---

## 付録

### 付録A：Gemini vs ChatGPT 編集機能比較
- GPT：編集すると後続プロンプトもリセット
- Gemini：最新入力のみ編集可能、前提は編集不可

### 付録B：参考リンク集
- Google Prompt Engineering Course
- TCREI詳細資料
- コンテキストウィンドウ研究論文
